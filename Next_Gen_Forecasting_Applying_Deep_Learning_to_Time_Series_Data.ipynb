{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPr6nq39WvhRAJUlQSq/Rns",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jayasurya227/Next-Gen-Forecasting-Applying-Deep-Learning-to-Time-Series-Data/blob/main/Next_Gen_Forecasting_Applying_Deep_Learning_to_Time_Series_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import Libraries And Dataset**"
      ],
      "metadata": {
        "id": "zeCa-_B4t8SJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "batFvsFbtbfW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from copy import deepcopy\n",
        "\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "df = pd.read_csv('data.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Preparation**"
      ],
      "metadata": {
        "id": "rQNu8MOjuGcf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def return_pairs(column, days):\n",
        "    pricess = list(column)\n",
        "    X = []\n",
        "    y = []\n",
        "    for i in range(len(pricess) - days):\n",
        "        X.append(pricess[i:i+days])\n",
        "        y.append(pricess[i+days])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "target_columns =  ['Open', 'Close', 'High', 'Low']\n",
        "day_chunks =  [30, 45, 60, 90, 120, 150 ,200, 250]\n",
        "\n",
        "chunked_data = {}\n",
        "\n",
        "for col in target_columns:\n",
        "    for days in day_chunks:\n",
        "        key_X = f\"X_{col}_{days}\"\n",
        "        key_y = f\"y_{col}_{days}\"\n",
        "        X, y = return_pairs(df[col], days)\n",
        "        chunked_data[key_X] = X\n",
        "        chunked_data[key_y] = y\n",
        "\n",
        "\n",
        "chunk_pairs = []\n",
        "\n",
        "for key in chunked_data.keys():\n",
        "    if key.startswith(\"X_\"):\n",
        "        y_key = key.replace(\"X_\", \"y_\")\n",
        "        if y_key in chunked_data:\n",
        "            chunk_pairs.append([key, y_key])"
      ],
      "metadata": {
        "id": "G-iHMUhkuB5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Neural Network Models**"
      ],
      "metadata": {
        "id": "gYYM3ysYuN_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, SimpleRNN, LSTM, GRU, Bidirectional\n",
        "\n",
        "\n",
        "def build_rnn(input_shape):\n",
        "    model = Sequential([\n",
        "        SimpleRNN(50, activation='tanh', input_shape=input_shape),\n",
        "        Dense(1)   # regression output\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "def build_lstm(input_shape):\n",
        "    model = Sequential([\n",
        "        LSTM(50, activation='tanh', input_shape=input_shape),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "def build_gru(input_shape):\n",
        "    model = Sequential([\n",
        "        GRU(50, activation='tanh', input_shape=input_shape),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "def build_bilstm(input_shape):\n",
        "    model = Sequential([\n",
        "        Bidirectional(LSTM(50, activation='tanh'), input_shape=input_shape),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model"
      ],
      "metadata": {
        "id": "hojuKHsAuJ_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Models**"
      ],
      "metadata": {
        "id": "NvHcxVzAuWwj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ml_models = [\n",
        "    (\"LinearRegression\", LinearRegression()),\n",
        "    (\"Ridge\", Ridge()),\n",
        "    (\"Lasso\", Lasso()),\n",
        "    (\"RandomForest\", RandomForestRegressor()),\n",
        "    (\"GradientBoosting\", GradientBoostingRegressor()),\n",
        "    (\"SVR\", SVR()),\n",
        "    (\"KNN\", KNeighborsRegressor()),\n",
        "    (\"XGBoost\", XGBRegressor(verbosity=0)),\n",
        "    (\"LightGBM\", LGBMRegressor(verbosity=0))\n",
        "]\n",
        "\n",
        "dl_models = {\n",
        "    \"RNN\": build_rnn,\n",
        "    \"LSTM\": build_lstm,\n",
        "    \"GRU\": build_gru,\n",
        "    \"Bidirectional_LSTM\": build_bilstm\n",
        "}"
      ],
      "metadata": {
        "id": "wPxjw6mIuTXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Training**"
      ],
      "metadata": {
        "id": "SOiMZf-7ueTd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trained_models = {}\n",
        "\n",
        "for X, y in tqdm(chunk_pairs):\n",
        "    X_data = chunked_data[X]\n",
        "    y_data = chunked_data[y]\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X_data, y_data, test_size=0.1, random_state=42\n",
        "    )\n",
        "\n",
        "    # ML models\n",
        "    for model_name, model in tqdm(ml_models):\n",
        "        key = model_name + '_' + X[2:]\n",
        "        model_copy = deepcopy(model)\n",
        "        model_copy.fit(X_train, y_train)\n",
        "\n",
        "        y_train_pred = model_copy.predict(X_train)\n",
        "        y_test_pred = model_copy.predict(X_test)\n",
        "\n",
        "        trained_models[key] = {\n",
        "            'model': model_copy,\n",
        "            'train_mae': mean_absolute_error(y_train, y_train_pred),\n",
        "            'train_rmse': np.sqrt(mean_squared_error(y_train, y_train_pred)),\n",
        "            'test_mae': mean_absolute_error(y_test, y_test_pred),\n",
        "            'test_rmse': np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "        }\n",
        "\n",
        "    # DL models\n",
        "    X_train_rnn = np.expand_dims(X_train, -1)\n",
        "    X_test_rnn = np.expand_dims(X_test, -1)\n",
        "\n",
        "    for model_name, builder in tqdm(dl_models.items()):\n",
        "        key = model_name + '_' + X[2:]\n",
        "        model_dl = builder((X_train.shape[1], 1))\n",
        "\n",
        "        model_dl.fit(X_train_rnn, y_train, epochs=10, batch_size=8, verbose=0)\n",
        "\n",
        "        y_train_pred = model_dl.predict(X_train_rnn).flatten()\n",
        "        y_test_pred = model_dl.predict(X_test_rnn).flatten()\n",
        "\n",
        "        trained_models[key] = {\n",
        "            'model': model_dl,\n",
        "            'train_mae': mean_absolute_error(y_train, y_train_pred),\n",
        "            'train_rmse': np.sqrt(mean_squared_error(y_train, y_train_pred)),\n",
        "            'test_mae': mean_absolute_error(y_test, y_test_pred),\n",
        "            'test_rmse': np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "        }\n"
      ],
      "metadata": {
        "id": "zRA5P6R6uaH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Saving Model Statistics**"
      ],
      "metadata": {
        "id": "H5vQjCmvup3H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_df = pd.DataFrame([\n",
        "    {\"Model\": name, **metrics}\n",
        "    for name, metrics in trained_models.items()])\n",
        "\n",
        "results_df.sort_values(by = 'test_mae', ascending = True).head(50)"
      ],
      "metadata": {
        "id": "mluMNQTeuhr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Top 50 Models**"
      ],
      "metadata": {
        "id": "vZlcyg1pu1Bj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "top_50 = results_df.sort_values(by='test_mae', ascending=True).head(50)\n",
        "\n",
        "plt.figure(figsize=(25, 8))\n",
        "plt.plot(top_50['Model'], top_50['train_mae'], marker='o', label='Train MAE')\n",
        "\n",
        "plt.plot(top_50['Model'], top_50['test_mae'], marker='o', label='Test MAE')\n",
        "\n",
        "plt.xticks(rotation=75)\n",
        "plt.xlabel('Model Name')\n",
        "plt.ylabel('MAE')\n",
        "plt.title('Top 50 Models: Train vs Test MAE (Line Chart)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kD1vfc-buyOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Relation BW No of Days And Model Perfomence**"
      ],
      "metadata": {
        "id": "rTKe-nhdu8qt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_50 = results_df.sort_values(by='test_mae', ascending=True).head(50)\n",
        "time_windows = pd.Series([i.split('_')[-1] for i in top_50['Model']])\n",
        "time_counts = time_windows.value_counts().sort_values(ascending=False)  # Sort by count\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.bar(time_counts.index, time_counts.values)\n",
        "\n",
        "# Labels and aesthetics\n",
        "plt.xlabel('Time Window (Days)')\n",
        "plt.ylabel('Number of Models in Top 50')\n",
        "plt.title('Frequency of Time Windows Among Top 50 Models (Lowest Test MAE)')\n",
        "plt.grid(axis='y')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2qnLgmg0u7da"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Which Column (High/Low/Open/Close) should be takaen into considiration for model building?**"
      ],
      "metadata": {
        "id": "FvbqQeH-vLwd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Extract target columns from top 50 models\n",
        "top_50 = results_df.sort_values(by='test_mae', ascending=True).head(50)\n",
        "target_columns = pd.Series([i.split('_')[-2] for i in top_50['Model']])\n",
        "target_counts = target_columns.value_counts().sort_values(ascending=False)  # Sort by count\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(target_counts.index, target_counts.values)\n",
        "\n",
        "# Labels and aesthetics\n",
        "plt.xlabel('Target Column')\n",
        "plt.ylabel('Number of Models in Top 50')\n",
        "plt.title('Target Column Frequency Among Top 50 Models (Lowest Test MAE)')\n",
        "plt.grid(axis='y')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "jdBiVQf7vKxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**which Model Works in general better on this task**"
      ],
      "metadata": {
        "id": "DdOLrtvZvl5M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_50 = results_df.sort_values(by='test_mae', ascending=True).head(50)\n",
        "model_types = pd.Series([i.split('_')[0] for i in top_50['Model']])\n",
        "model_counts = model_types.value_counts().sort_values(ascending=False)\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.bar(model_counts.index, model_counts.values)\n",
        "\n",
        "# Labels and aesthetics\n",
        "plt.xlabel('Model Type')\n",
        "plt.ylabel('Number of Models in Top 50')\n",
        "plt.title('Model Type Frequency Among Top 50 Models (Lowest Test MAE)')\n",
        "plt.grid(axis='y')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "g2I3la4ivhP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Saving Model**"
      ],
      "metadata": {
        "id": "PZJLXBAEvz0u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "results_df.to_csv('models.csv')\n",
        "joblib.dump(trained_models, 'trained_models.joblib')\n",
        "\n",
        "loaded_models = joblib.load('trained_models.joblib')"
      ],
      "metadata": {
        "id": "j9_CIpbvvy5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading Saved Model**"
      ],
      "metadata": {
        "id": "sl7eeJ-rv7Zs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_models['KNN_High_90']\n",
        "model = loaded_models['KNN_High_90']['model']"
      ],
      "metadata": {
        "id": "QhPh096Tv3M6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Inferance**"
      ],
      "metadata": {
        "id": "hXF1m4E2wC5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(chunked_data['X_Open_90'][5])\n",
        "print(model.predict([chunked_data['X_Open_90'][5]]))"
      ],
      "metadata": {
        "id": "UoYfpFa4v_Mb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}